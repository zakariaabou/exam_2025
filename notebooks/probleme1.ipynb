{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Problème n°1"
      ],
      "metadata": {
        "id": "GYE9s4-HA1o_"
      },
      "id": "GYE9s4-HA1o_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "La bonne transmission de signaux électromagnétiques dans l'atmosphère peut dépendre de la météo. La pluie affecte notoirement les échanges entre les antennes relais des réseaux mobiles actuels. C'est une gêne, mais aussi une opportunité: l'atténuation des ondes électromagnétiques due à la pluie peut être mesurée et utilisée comme un moyen de quantifier les précipitations.\n",
        "\n",
        "Dans ce problème, on s'intéresse à la conversion de l'atténuation, définie comme un rapport entre puissance émise et puissance reçue et exprimée en dB, en un taux de pluie moyen le long de segments physiques dont les extrémités sont des paires d'antennes relais.\n",
        "\n",
        "Evidemment, d'autres éléments que le pluie, plus ou moins bien connus, peuvent influencer l'atténuation. La simulation sur laquelle nous allons travailler, qui porte sur un millier de paires d'antennes virtuelles, est construite de la façon suivante:\n",
        "\n",
        "- pour une paire d'antennes donnée, on modélise une série temporelle de taux de pluie moyen par un processus stochastique dont les paramètres dépendent entre autres de la distance qui sépare les antennes.\n",
        "- pour en tirer des atténuations, on applique à cette série les transformations suivantes:\n",
        "    - un filtre convolutif, censé modéliser l'impact du film d'eau se formant sur les antennes au cours d'un épisode de pluie.\n",
        "    - une conversion non-linéaire, tirée d'un modèle physique, est appliquée composante à composante.\n",
        " épisode pluvieux (ce film qui s'épaissit augmente progressivement l'atténuation).\n",
        "    - un bruit haute-fréquence\n",
        "    - un bruit basse fréquence\n",
        "\n",
        "La cellules suivantes permettent de récupérer les briques de code utiles, de construire un dictionnaire contenant des identifiants de paires d'antennes (clefs) et les distances les séparant (valeurs). La dernière cellule montre des exemples de séries temporelles simulées pour quelques paires."
      ],
      "metadata": {
        "id": "u3Htf2k4rs_9"
      },
      "id": "u3Htf2k4rs_9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf3477e5-ac2b-4cf8-9de3-e95782130327",
      "metadata": {
        "id": "cf3477e5-ac2b-4cf8-9de3-e95782130327",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Local clone\n",
        "! git clone https://github.com/XXXXXX/exam_2025.git\n",
        "! cp exam_2025/utils/utils_probleme1.py ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0u1PXBYMSD-f",
      "metadata": {
        "id": "0u1PXBYMSD-f"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from os.path import join, isdir, isfile\n",
        "from os import listdir as ls\n",
        "import copy\n",
        "import torch\n",
        "import numpy as np\n",
        "import sys\n",
        "from utils_probleme1 import create_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "iywu4Uq-e2rx",
      "metadata": {
        "id": "iywu4Uq-e2rx"
      },
      "outputs": [],
      "source": [
        "# Dictionnaire des \"distances\" (générées au hasard)\n",
        "idx2distance_train = {i: 0.2 +  1.8 * torch.rand((1,)).item() for i in range(0, 1000)}\n",
        "idx2distance_val = {i: 0.2 +  1.8 * torch.rand((1,)).item() for i in range(1000, 1200)}\n",
        "\n",
        "# Paramètres de la simulation\n",
        "duration = 4096  # durée de la série temporelle (unité : minutes)\n",
        "batch_size = 100  # taille d'un échantillon\n",
        "\n",
        "# Création du dataloader (il contient toutes les étapes de la simulation)\n",
        "# (en une époque, chaque paire d'antennes du dictionnaire idx2distance\n",
        "# a été tirée exactement une fois)\n",
        "trainloader = create_dataloader(duration, idx2distance_train, batch_size)\n",
        "\n",
        "# Génération d'un batch contenant des séries temporelles\n",
        "for batch_idx, (ids, dists, rain_rates, attenuations) in enumerate(trainloader):\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TUb6dcqOQNcp",
      "metadata": {
        "id": "TUb6dcqOQNcp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for k in range(5):\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.plot(np.arange(duration), rain_rates[k], label='rain rates')\n",
        "  plt.plot(np.arange(duration), attenuations[k], label='attenuations')\n",
        "  plt.title(f\"Attenuations et taux de pluie moyen pour la paire n°{ids[k].item():.0f} (distance: {dists[k].item():.2f} km)\")\n",
        "  plt.xlabel('Time (minutes)')\n",
        "  plt.ylabel('DB (atten.) ou mm/h (pluie)')\n",
        "  plt.ylim(-1,6)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partie I : Un réseau de neurones générique"
      ],
      "metadata": {
        "id": "d3YafgwcEWdg"
      },
      "id": "d3YafgwcEWdg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A partir des briques de base"
      ],
      "metadata": {
        "id": "8DREH0tGKWF_"
      },
      "id": "8DREH0tGKWF_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cette partie, on entraîne un UNet1D à faire le lien entre atténuations\n",
        "et taux de pluie. Les cellules suivantes contiennent les blocs du UNet1D et son montage :"
      ],
      "metadata": {
        "id": "0tcQiphyJ9nP"
      },
      "id": "0tcQiphyJ9nP"
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################################\n",
        "################################     UNet 1D building blokcs    ##############################\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class double_conv(nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2'''\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm1d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv1d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm1d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class inconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(inconv, self).__init__()\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(Down, self).__init__()\n",
        "        self.mpconv = nn.Sequential(\n",
        "            nn.MaxPool1d(2),\n",
        "            double_conv(in_ch, out_ch)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mpconv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, bilinear=False):\n",
        "        super(Up, self).__init__()\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear')\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose1d(in_ch, in_ch, kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv = double_conv(2*in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffX = x1.size()[2] - x2.size()[2]\n",
        "        x2 = F.pad(x2, (diffX // 2, int(diffX / 2)))\n",
        "\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class outconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(outconv, self).__init__()\n",
        "        self.conv = nn.Conv1d(in_ch, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "################################################################################\n",
        "######################################## class UNet1D ##########################\n",
        "\n",
        "class UNet1D(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, size=64):\n",
        "        super(UNet1D, self).__init__()\n",
        "        self.inc = inconv(n_channels, size)\n",
        "        self.down1 = Down(size, 2*size)\n",
        "        self.down2 = Down(2*size, 4*size)\n",
        "        self.down3 = Down(4*size, 8*size)\n",
        "        self.down4 = Down(8*size, 8*size)\n",
        "        self.up1 = Up(8*size, 4*size)\n",
        "        self.up2 = Up(4*size, 2*size)\n",
        "        self.up3 = Up(2*size, size)\n",
        "        self.up4 = Up(size, size)\n",
        "        self.outc = outconv(size, n_classes)\n",
        "        self.n_classes=n_classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        del x4, x5\n",
        "        x = self.up2(x, x3)\n",
        "        del x3\n",
        "        x = self.up3(x, x2)\n",
        "        del x2\n",
        "        x = self.up4(x, x1)\n",
        "        del x1\n",
        "        x = self.outc(x)\n",
        "        return   x"
      ],
      "metadata": {
        "id": "tCdRYlU9HWqg"
      },
      "id": "tCdRYlU9HWqg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Consignes:** \\\n",
        "1) Entraîner sur GPU un UNet 1D à restituer les taux de pluie à partir des atténuations.\n",
        "- On utilisera la MSE comme fonction de coût et comme score. Dans les deux cas, prendre une marge de deux heures au début et à la fin de la série temporelle pour éviter les effets de bord.\n",
        "- La descente de gradient stochastique sera pilotée par l'optimiseur ADAM (paramétrage standard) sur cinquante époques.\n",
        "\n",
        "2) Tracer la courbe d'apprentissage de manière à montrer l'évolution:\n",
        "- des performances en généralisation sur de nouvelles données issues des paires d'antennes vues à l'entraînement.\n",
        "- des performances en généralisation sur des séries issues de paires d'antennes indépendantes (celles de *idx2distance_val*).\n",
        "\n",
        "\n",
        "3) Visualiser les prédictions après apprentissage"
      ],
      "metadata": {
        "id": "Q3-U8nl4O9-R"
      },
      "id": "Q3-U8nl4O9-R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92ab6b68-0814-416f-9c23-85dfa0b7bba8",
      "metadata": {
        "id": "92ab6b68-0814-416f-9c23-85dfa0b7bba8"
      },
      "outputs": [],
      "source": [
        "n_channels = ...\n",
        "n_classes = ...\n",
        "model = UNet1D(n_channels, n_classes, size=32)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partie II\n",
        "\n",
        "Dans la première partie, le modèle était générique: la specificité de la paire d'antenne n'était pas prise en compte. On se propose de le faire en combinant un réseau générique à un perceptron spécifique, de sorte que la sortie $Z$ s'exprime sous la forme: \\\n",
        "$$Z = F(X, k) = f^{\\tiny{Perceptron}}_{\\alpha_k}(f^{\\tiny{UNet}}_{\\theta}(X))$$ \\\n",
        " où $f^{\\tiny{UNet}}_{\\theta}(.)$ représente la fonction *forward* d'un UNet et $f^{\\tiny{Perceptron}}_{\\alpha_k}(.)$, la fonction forward du perceptron associé à la paire d'antennes d'identifiant $k$. \\\n",
        "\n",
        "Il s'agit donc en premier lieu d'adjoindre au UNet de la partie I autant de perceptrons que le jeu d'entraînement compte de paires d'antennes, ce qui se fait grâce aux lignes suivantes:"
      ],
      "metadata": {
        "id": "HAoMD5X7E2SH"
      },
      "id": "HAoMD5X7E2SH"
    },
    {
      "cell_type": "code",
      "source": [
        "# Pour l'ajout de 1200 perceptrons à deux couches:\n",
        "self.num_pairs = 1200\n",
        "self.input_size_fc_layer = 5\n",
        "self.hidden_size_fc_layer = 5\n",
        "# Liste des premières couches\n",
        "self.linears1 = nn.ModuleList([nn.Linear(self.input_size_fc_layer,\n",
        "                                         self.hidden_size_fc_layer) for i in range(self.num_pairs)])\n",
        "# Liste des secondes couches\n",
        "self.linears2 = nn.ModuleList([nn.Linear(self.hidden_size_fc_layer,\n",
        "                                         1) for i in range(self.num_pairs)])\n"
      ],
      "metadata": {
        "id": "lKV66NKbkbSz"
      },
      "id": "lKV66NKbkbSz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Consignes:** \\\n",
        "1) Définir une nouvelle classe de réseau en modifiant la classe UNet1D (dans utils_probleme1.py).\n",
        "Ajouter ces perceptrons au réseau.\n",
        "\n",
        "2) Fixer *self.n_classes* de façon à ce que la sortie du UNet soit compatible avec l'entrée du perceptron.\n",
        "\n",
        "3) Modifications de la fonction forward:\n",
        "- elle doit prendre comme arguments un batch d'entrées et un batch d'identifiants.\n",
        "\n",
        "- après les étapes propres au UNet, elle doit appliquer le perceptron d'indice k à une série provenant de la paire n°k. La cellule de code suivante fournit un exemple dont on pourra directement s'inspirer.\n",
        "\n",
        "4) Suivre les performances en généralisation sur les paires d'antennes du jeu d'entraînement et sur les deux cents paires de validation. Commenter.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CtUCwEltX7fy"
      },
      "id": "CtUCwEltX7fy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tFGXzz6xh4ir",
      "metadata": {
        "id": "tFGXzz6xh4ir"
      },
      "outputs": [],
      "source": [
        "def apply_perceptron(self, UNet_output, ids):\n",
        "    for i in range(ids.shape[0]):\n",
        "        id = ids[i]\n",
        "        # application de la première couche\n",
        "        x = self.linears1[id](UNet_output[i].transpose(0,1).contiguous())\n",
        "        x = self.relu(x)\n",
        "        # application de la seconde couche\n",
        "        x = self.linears2[id](x)\n",
        "        # correction multiplicative de UNet_output\n",
        "        UNet_output[i, 0] *= 1 + x.transpose(0,1).contiguous()\n",
        "    return UNet_output[:,0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partie III\n",
        "\n",
        "La solution proposée dans la partie II a un défaut: les performances chutent sur les paires d'antennes qui n'ont pas été rencontrées pendant l'entraînement. Pour le corriger, on se propose de suivre la méthode suivante:\n",
        "- ajouter un perceptron \"générique\" de même architecture que les perceptrons spécifiques.\n",
        "- entraîner le réseau de la partie II en remplaçant une fois sur quatre l'identifiant de la paire d'antennes par l'indice du perceptron générique.\n",
        "- après cinquante époques, geler les poids de la partie générique et prolonger l'apprentissage des perceptrons spécifiques sur une vingtaine d'époque.\n",
        "\n",
        "**Consignes:** \\\n",
        "\n",
        "1) Mettre en oeuvre cette méthode\n",
        "\n",
        "2) Conclure sur son efficacité"
      ],
      "metadata": {
        "id": "gLloZqn-umi8"
      },
      "id": "gLloZqn-umi8"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cTCs6AZ-e6dD"
      },
      "id": "cTCs6AZ-e6dD",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}